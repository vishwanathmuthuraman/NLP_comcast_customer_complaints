{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Consumer complaints topic extraction using Latent diriclect allocation (LDA) and Latent semantic analysis (LSA)\n",
    "LSA is a method of analyzing text data using principal component analysis. LDA is a probabilistic approach, utilizing the Dirichlet distribution. Over-fitting is less likely with LDA since it uses priors.\n",
    "\n",
    "Additionally, both documents and words are represented by orthogonal vectors. LDA is concerned with independent topics, while LSA is concerned with orthogonal representations.\n",
    "\n",
    "Lastly, LDA requires a minimum number of topics or components. K is selected as the most effective method for capturing the majority of variations in the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comcast consumer complaint dataset\n",
    "\n",
    "This dataset was obtained from kaggle and made readily available to all by charlie.H. This data set contains 2 CSV files.\n",
    "1. comcast_consumeraffairs_complaints.csv\n",
    "2. comcast_fcc_complaints_2015.csv\n",
    "\n",
    "The first data set however is more beneficial for sentiment analysis. We will be working with the second dataset today comcast_fcc_complaints_2015.csv. it contains several columns including one with verbatim which we will use for topic extraction."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initializing packages and exploring the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Kumarappan\n",
      "[nltk_data]     M\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Kumarappan\n",
      "[nltk_data]     M\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "     Ticket #                                 Customer Complaint       Date  \\\n0      250635                      Comcast Cable Internet Speeds  4/22/2015   \n1      223441       Payment disappear - service got disconnected   4/8/2015   \n2      242732                                  Speed and Service  4/18/2015   \n3      277946  Comcast Imposed a New Usage Cap of 300GB that ...   5/7/2015   \n4      307175         Comcast not working and no service to boot  5/26/2015   \n...       ...                                                ...        ...   \n2220   213550                               Service Availability   4/2/2015   \n2221   318775         Comcast Monthly Billing for Returned Modem   6/2/2015   \n2222   331188                            complaint about comcast   6/9/2015   \n2223   360489             Extremely unsatisfied Comcast customer  6/23/2015   \n2224   363614               Comcast, Ypsilanti MI Internet Speed  6/24/2015   \n\n             Time Received Via        City     State  Zip code  Status  \\\n0      3:53:50 PM     Internet    Abingdon  Maryland     21009  Closed   \n1     10:22:56 AM     Internet     Acworth   Georgia     30102  Closed   \n2      9:55:47 AM     Internet     Acworth   Georgia     30101  Closed   \n3     11:59:35 AM     Internet     Acworth   Georgia     30101    Open   \n4      1:25:26 PM     Internet     Acworth   Georgia     30101  Solved   \n...           ...          ...         ...       ...       ...     ...   \n2220   9:13:18 AM     Internet  Youngstown   Florida     32466  Closed   \n2221   1:24:39 PM     Internet   Ypsilanti  Michigan     48197  Solved   \n2222   5:28:41 PM     Internet   Ypsilanti  Michigan     48197  Solved   \n2223  11:13:30 PM     Internet   Ypsilanti  Michigan     48197  Solved   \n2224  10:28:33 PM     Internet   Ypsilanti  Michigan     48198    Open   \n\n     Filing on Behalf of Someone  \\\n0                             No   \n1                             No   \n2                            Yes   \n3                            Yes   \n4                             No   \n...                          ...   \n2220                          No   \n2221                          No   \n2222                          No   \n2223                          No   \n2224                         Yes   \n\n                                            Description  \n0     I have been contacting Comcast Internet Techni...  \n1     Back in January 2015 I made 2 payments: One fo...  \n2     Our home is located at in Acworth Georgia 3010...  \n3     Comcast in the Atlanta area has just put into ...  \n4     I have been a customer of Comcast of some sort...  \n...                                                 ...  \n2220  I am a deaf guy. I have asked ATT or Comcast t...  \n2221  We purchased our own modem and returned the Co...  \n2222  i had an agreement with comcast agent 1 year f...  \n2223  A few months ago I was forced to finally call ...  \n2224  My Internet disconnects all of the time and I ...  \n\n[2225 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ticket #</th>\n      <th>Customer Complaint</th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Received Via</th>\n      <th>City</th>\n      <th>State</th>\n      <th>Zip code</th>\n      <th>Status</th>\n      <th>Filing on Behalf of Someone</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>250635</td>\n      <td>Comcast Cable Internet Speeds</td>\n      <td>4/22/2015</td>\n      <td>3:53:50 PM</td>\n      <td>Internet</td>\n      <td>Abingdon</td>\n      <td>Maryland</td>\n      <td>21009</td>\n      <td>Closed</td>\n      <td>No</td>\n      <td>I have been contacting Comcast Internet Techni...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>223441</td>\n      <td>Payment disappear - service got disconnected</td>\n      <td>4/8/2015</td>\n      <td>10:22:56 AM</td>\n      <td>Internet</td>\n      <td>Acworth</td>\n      <td>Georgia</td>\n      <td>30102</td>\n      <td>Closed</td>\n      <td>No</td>\n      <td>Back in January 2015 I made 2 payments: One fo...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>242732</td>\n      <td>Speed and Service</td>\n      <td>4/18/2015</td>\n      <td>9:55:47 AM</td>\n      <td>Internet</td>\n      <td>Acworth</td>\n      <td>Georgia</td>\n      <td>30101</td>\n      <td>Closed</td>\n      <td>Yes</td>\n      <td>Our home is located at in Acworth Georgia 3010...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>277946</td>\n      <td>Comcast Imposed a New Usage Cap of 300GB that ...</td>\n      <td>5/7/2015</td>\n      <td>11:59:35 AM</td>\n      <td>Internet</td>\n      <td>Acworth</td>\n      <td>Georgia</td>\n      <td>30101</td>\n      <td>Open</td>\n      <td>Yes</td>\n      <td>Comcast in the Atlanta area has just put into ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>307175</td>\n      <td>Comcast not working and no service to boot</td>\n      <td>5/26/2015</td>\n      <td>1:25:26 PM</td>\n      <td>Internet</td>\n      <td>Acworth</td>\n      <td>Georgia</td>\n      <td>30101</td>\n      <td>Solved</td>\n      <td>No</td>\n      <td>I have been a customer of Comcast of some sort...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2220</th>\n      <td>213550</td>\n      <td>Service Availability</td>\n      <td>4/2/2015</td>\n      <td>9:13:18 AM</td>\n      <td>Internet</td>\n      <td>Youngstown</td>\n      <td>Florida</td>\n      <td>32466</td>\n      <td>Closed</td>\n      <td>No</td>\n      <td>I am a deaf guy. I have asked ATT or Comcast t...</td>\n    </tr>\n    <tr>\n      <th>2221</th>\n      <td>318775</td>\n      <td>Comcast Monthly Billing for Returned Modem</td>\n      <td>6/2/2015</td>\n      <td>1:24:39 PM</td>\n      <td>Internet</td>\n      <td>Ypsilanti</td>\n      <td>Michigan</td>\n      <td>48197</td>\n      <td>Solved</td>\n      <td>No</td>\n      <td>We purchased our own modem and returned the Co...</td>\n    </tr>\n    <tr>\n      <th>2222</th>\n      <td>331188</td>\n      <td>complaint about comcast</td>\n      <td>6/9/2015</td>\n      <td>5:28:41 PM</td>\n      <td>Internet</td>\n      <td>Ypsilanti</td>\n      <td>Michigan</td>\n      <td>48197</td>\n      <td>Solved</td>\n      <td>No</td>\n      <td>i had an agreement with comcast agent 1 year f...</td>\n    </tr>\n    <tr>\n      <th>2223</th>\n      <td>360489</td>\n      <td>Extremely unsatisfied Comcast customer</td>\n      <td>6/23/2015</td>\n      <td>11:13:30 PM</td>\n      <td>Internet</td>\n      <td>Ypsilanti</td>\n      <td>Michigan</td>\n      <td>48197</td>\n      <td>Solved</td>\n      <td>No</td>\n      <td>A few months ago I was forced to finally call ...</td>\n    </tr>\n    <tr>\n      <th>2224</th>\n      <td>363614</td>\n      <td>Comcast, Ypsilanti MI Internet Speed</td>\n      <td>6/24/2015</td>\n      <td>10:28:33 PM</td>\n      <td>Internet</td>\n      <td>Ypsilanti</td>\n      <td>Michigan</td>\n      <td>48198</td>\n      <td>Open</td>\n      <td>Yes</td>\n      <td>My Internet disconnects all of the time and I ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2225 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from gensim.models import LsiModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('comcast_fcc_complaints_2015.csv')\n",
    "display(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 11 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   Ticket #                     2225 non-null   object\n",
      " 1   Customer Complaint           2225 non-null   object\n",
      " 2   Date                         2225 non-null   object\n",
      " 3   Time                         2225 non-null   object\n",
      " 4   Received Via                 2225 non-null   object\n",
      " 5   City                         2225 non-null   object\n",
      " 6   State                        2225 non-null   object\n",
      " 7   Zip code                     2225 non-null   int64 \n",
      " 8   Status                       2225 non-null   object\n",
      " 9   Filing on Behalf of Someone  2225 non-null   object\n",
      " 10  Description                  2225 non-null   object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 191.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Complaint Categories\n",
    "\n",
    "The column \"customer Complaints\" contains the different categories each complaint falls under. On further analysis, we find that there are 1842 categories. This probably is not the case, most customers file their issues under wrong categories by using LDA and LSA we can effectively classify these complaints into n number of topics of our choice."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "Comcast                                          83\nComcast Internet                                 18\nComcast Data Cap                                 17\ncomcast                                          13\nComcast Data Caps                                11\n                                                 ..\nImproper Billing and non resolution of issues     1\nDeceptive trade                                   1\nintermittent internet                             1\nInternet Speed on Wireless Connection             1\nComcast, Ypsilanti MI Internet Speed              1\nName: Customer Complaint, Length: 1842, dtype: int64"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Customer Complaint'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Pre-Processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Tokenization\n",
    "#### 2. lemmatization\n",
    "#### 3. stemming"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def lemma_stem(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemma_stem(token))\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regular Split Vs Stemmer Difference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed original document using a regular split(): \n",
      "[['Comcast', 'Cable', 'Internet', 'Speeds'], ['Payment', 'disappear', '-', 'service', 'got', 'disconnected'], ['Speed', 'and', 'Service'], ['Comcast', 'Imposed', 'a', 'New', 'Usage', 'Cap', 'of', '300GB', 'that', 'punishes', 'streaming.'], ['Comcast', 'not', 'working', 'and', 'no', 'service', 'to', 'boot']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Stemmed original document using a regular split(): \")\n",
    "words = []\n",
    "for word in df['Customer Complaint'].str.split(' '):\n",
    "    words.append(word)\n",
    "print(words[:5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               [comcast, cabl, internet, speed]\n",
      "1       [payment, disappear, servic, disconnect]\n",
      "2                                [speed, servic]\n",
      "3         [comcast, impos, usag, punish, stream]\n",
      "4                  [comcast, work, servic, boot]\n",
      "                          ...                   \n",
      "2220                             [servic, avail]\n",
      "2221       [comcast, month, bill, return, modem]\n",
      "2222                        [complaint, comcast]\n",
      "2223        [extrem, unsatisfi, comcast, custom]\n",
      "2224       [comcast, ypsilanti, internet, speed]\n",
      "Name: Customer Complaint, Length: 2225, dtype: object\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "print(df['Customer Complaint'].fillna('').astype(str).map(preprocess))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "processed_docs = []\n",
    "\n",
    "for doc in df['Customer Complaint'].fillna('').astype(str):\n",
    "    processed_docs.append(preprocess(doc))\n",
    "\n",
    "# For LSA\n",
    "df['Text (Clean)'] = df['Customer Complaint'].apply(lambda x: preprocess(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bag of Words ( BoW )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we create a dictionary of the number of times each word occurs across the corpus by using the gensim package's dictionary function. This will be used as a parameter 'ID2' for our LDA model later."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cabl\n",
      "1 comcast\n",
      "2 internet\n",
      "3 speed\n",
      "4 disappear\n",
      "5 disconnect\n",
      "6 payment\n",
      "7 servic\n",
      "8 impos\n",
      "9 punish\n",
      "10 stream\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break\n",
    "\n",
    "# We now filter words that occur less than 5 times and those occurring more than half the time.\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gensim doc2bow\n",
    "\n",
    "Each document in the corpus is assigned a BoW model by Doc2bow. An index of the number of times each word appears in a document is produced as a result."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Latent Dirichlect Allocation (LDA)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "lda_model =  gensim.models.LdaMulticore(bow_corpus,\n",
    "                                        num_topics = 6,\n",
    "                                        id2word = dictionary,\n",
    "                                        passes = 10,\n",
    "                                        workers = 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.277*\"internet\" + 0.151*\"bill\" + 0.107*\"speed\" + 0.082*\"servic\" + 0.041*\"throttl\" + 0.038*\"issu\" + 0.036*\"practic\" + 0.034*\"slow\" + 0.024*\"unfair\" + 0.021*\"connect\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.143*\"complaint\" + 0.106*\"servic\" + 0.059*\"bill\" + 0.052*\"bundl\" + 0.040*\"custom\" + 0.039*\"charg\" + 0.038*\"modem\" + 0.037*\"refus\" + 0.026*\"refund\" + 0.024*\"issu\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.086*\"issu\" + 0.085*\"cabl\" + 0.061*\"problem\" + 0.053*\"price\" + 0.051*\"lie\" + 0.043*\"monopoli\" + 0.039*\"servic\" + 0.037*\"instal\" + 0.035*\"increas\" + 0.028*\"fraud\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.243*\"servic\" + 0.105*\"xfiniti\" + 0.077*\"price\" + 0.072*\"custom\" + 0.070*\"charg\" + 0.039*\"internet\" + 0.031*\"poor\" + 0.030*\"provid\" + 0.022*\"cancel\" + 0.019*\"failur\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.073*\"servic\" + 0.058*\"advertis\" + 0.049*\"contract\" + 0.044*\"fals\" + 0.043*\"decept\" + 0.042*\"busi\" + 0.040*\"overcharg\" + 0.036*\"month\" + 0.033*\"switch\" + 0.032*\"block\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.317*\"data\" + 0.120*\"cap\" + 0.068*\"usag\" + 0.043*\"charg\" + 0.032*\"account\" + 0.032*\"limit\" + 0.030*\"overag\" + 0.024*\"disconnect\" + 0.023*\"fraudul\" + 0.020*\"terribl\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### The model has produced five outputs. Using these five topics, it is possible to categorize all the words in the corpus. The LDA model, however, does not provide us with the topic names. we infer that from the results or we could use print_topics from pprint."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Manual Topic Classification Based on the above output\n",
    "\n",
    "1. Concern\n",
    "2. High-speed\n",
    "3. Disappointing\n",
    "4. Surcharge\n",
    "5. Deceit\n",
    "6. Bandwidth"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluation\n",
    "\n",
    "There are two methods that could be leveraged to evaluate a LDA model, coherence and perplexity. Uncertainty is measured by perplexity, so the lower the perplexity, the more accurate the model. This is what we will be using today. As you can see the model performed well with a score of -4.58901\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity Metric:  -4.589018458625131\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity Metric: ', lda_model.log_perplexity(bow_corpus))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Latent Semantic Analysis ( LSA )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence score with 2 Topics: 0.4645335830295454\n",
      "Coherence score with 3 Topics: 0.5198620542268798\n",
      "Coherence score with 4 Topics: 0.5055562631148034\n",
      "Coherence score with 5 Topics: 0.49671675404803917\n",
      "Coherence score with 6 Topics: 0.5762340683961888\n",
      "Coherence score with 7 Topics: 0.5198443217579267\n",
      "Coherence score with 8 Topics: 0.5670752174275087\n",
      "Coherence score with 9 Topics: 0.535671527047652\n",
      "Coherence score with 10 Topics: 0.5509608793514204\n"
     ]
    }
   ],
   "source": [
    "# Calculate the coherence score when you have a different number of topics\n",
    "for i in range(2,11):\n",
    "    lsi = LsiModel(bow_corpus, num_topics=i, id2word=dictionary)\n",
    "    coherence_model = CoherenceModel(model=lsi, texts=df['Text (Clean)'], dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    print('Coherence score with {} Topics: {}'.format(i, coherence_score))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### When performing SVD, we will extract the topics with the highest coherence score. The strongest associations each topic has with 5 words are selected here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Extract 2 topics from the bag of words using SVD and the LsiModel\n",
    "lsi = LsiModel(bow_corpus, num_topics=6, id2word=dictionary)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in 0: 0.677*\"servic\" + 0.645*\"internet\" + 0.197*\"bill\" + 0.164*\"speed\" + 0.122*\"custom\".\n",
      "Words in 1: 0.675*\"internet\" + -0.607*\"servic\" + 0.252*\"speed\" + -0.239*\"bill\" + -0.150*\"custom\".\n",
      "Words in 2: 0.870*\"bill\" + -0.322*\"servic\" + 0.228*\"practic\" + 0.188*\"issu\" + 0.153*\"unfair\".\n",
      "Words in 3: -0.886*\"data\" + -0.376*\"cap\" + -0.169*\"usag\" + -0.108*\"charg\" + 0.106*\"bill\".\n",
      "Words in 4: 0.896*\"speed\" + -0.321*\"internet\" + 0.158*\"throttl\" + 0.116*\"charg\" + 0.088*\"advertis\".\n",
      "Words in 5: -0.939*\"charg\" + -0.136*\"price\" + 0.112*\"speed\" + -0.107*\"modem\" + 0.094*\"data\".\n"
     ]
    }
   ],
   "source": [
    "for topic_num, words in lsi.print_topics(num_words=5):\n",
    "    print('Words in {}: {}.'.format(topic_num, words))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### We can now see how the model scores each word based on the topic assigned to it. Documents can contain a number of topics, but some topics are closely related. This helps us determine the topic a document is associated with."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "                               Text  \\\n0  [comcast, cabl, internet, speed]   \n\n                                       Topic 0 score  \\\n0  [(0, 0.84603426514624), (1, 0.9635160138261774...   \n\n                                       Topic 1 score  \\\n0  [(0, 0.84603426514624), (1, 0.9635160138261774...   \n\n                                               Topic  \n0  [(0, 0.84603426514624), (1, 0.9635160138261774...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Topic 0 score</th>\n      <th>Topic 1 score</th>\n      <th>Topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[comcast, cabl, internet, speed]</td>\n      <td>[(0, 0.84603426514624), (1, 0.9635160138261774...</td>\n      <td>[(0, 0.84603426514624), (1, 0.9635160138261774...</td>\n      <td>[(0, 0.84603426514624), (1, 0.9635160138261774...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_lsi = lsi[bow_corpus]\n",
    "score1 = []\n",
    "score2 = []\n",
    "for doc in corpus_lsi:\n",
    "    score1.append(doc)\n",
    "    score2.append(doc)\n",
    "\n",
    "# create data frame that shows scores assigned for both topics for each review\n",
    "df_topic = pd.DataFrame()\n",
    "df_topic['Text'] = df['Text (Clean)']\n",
    "df_topic['Topic 0 score'] = score1\n",
    "df_topic['Topic 1 score'] = score2\n",
    "from operator import itemgetter\n",
    "df_topic['Topic']= df_topic[['Topic 0 score', 'Topic 1 score']].apply(lambda x: x.max(), axis=1)\n",
    "df_topic.head(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above is just an example with 2 topics, but it shows you the score related to each topic of a document allowing us to determine which topic best resembles the document."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
